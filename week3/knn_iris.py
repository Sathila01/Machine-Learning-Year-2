# -*- coding: utf-8 -*-
"""KNN-Iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zhGrHAvf78afix01u9LkVuPfY4-qhVJN
"""

# import libs
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets

# import some data to play with
irisData = datasets.load_iris()
irisData.data

"""**Attribute Information**
    - sepal length in cm
    - sepal width in cm
    - petal length in cm
    - petal width in cm
    - class:
            - Iris-Setosa
            - Iris-Versicolour
            - Iris-Virginica
"""

# we only take the first two features for learning purpose
X = irisData.data[:, :2]
y = irisData.target

n_neighbors = 15

"""The basic nearest neighbors classification uses uniform weights: that is, the value assigned to a query point is computed from a simple majority vote of the nearest neighbors. Under some circumstances, it is better to weight the neighbors such that nearer neighbors contribute more to the fit. <br>
This can be accomplished through the weights keyword. <br>
The default value, **weights = 'uniform'**, assigns uniform weights to each neighbor. <br>
**weights = 'distance'** assigns weights proportional to the inverse of the distance from the query point.
"""

# Commented out IPython magic to ensure Python compatibility.
step = .01  # step size in the mesh

for weights in ['uniform', 'distance']:
    # we create an instance of Neighbours Classifier and fit the data.
    classifier = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
    classifier.fit(X, y)
    
    print('KNN classifier accuracy - "%s" - %.3f' % (weights,classifier.score(X,y)))
    
    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, x_max]x[y_min, y_max].
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    x_grid, y_grid = np.meshgrid(np.arange(x_min, x_max, step = step),
                         np.arange(y_min, y_max, step = step))
    Z = classifier.predict(np.c_[x_grid.ravel(), y_grid.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(x_grid.shape)
    plt.figure()
    plt.pcolormesh(x_grid, y_grid, Z, cmap=ListedColormap(['lightblue', 'lightgreen', 'lightyellow']) )

    # Plot also the training points
    plt.scatter(X[:, 0], X[:, 1], c=y, 
                edgecolor='k', s=20)
    plt.xlim(x_grid.min(), x_grid.max())
    plt.ylim(y_grid.min(), y_grid.max())
    plt.title("KNN 3-Class Classification (k = %d, weights = '%s')"
#               % (n_neighbors, weights))


plt.show()

"""### Visualization - Detailed"""

weights ='uniform'
# we create an instance of Neighbours Classifier and fit the data.
classifier = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
classifier.fit(X, y)

print('KNN classifier accuracy - "%s" - %.3f' % (weights,classifier.score(X,y)))

# Plot the decision boundary. For that, we will assign a color to each
# point in the mesh [x_min, x_max]x[y_min, y_max].
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

x_grid, y_grid = np.meshgrid(np.arange(x_min, x_max, step = step),
                     np.arange(y_min, y_max, step = step))

x_grid

y_grid

Z = classifier.predict(np.array([x_grid.ravel(), y_grid.ravel()]).T).reshape(x_grid.shape)

np.array([x_grid.ravel(), y_grid.ravel()])

np.array([x_grid.ravel(), y_grid.ravel()]).shape

np.array([x_grid.ravel(), y_grid.ravel()]).T

classifier.predict(np.array([x_grid.ravel(), y_grid.ravel()]).T)

classifier.predict(np.array([x_grid.ravel(), y_grid.ravel()]).T).reshape(x_grid.shape)

# Commented out IPython magic to ensure Python compatibility.
plt.figure()
plt.contourf(x_grid, y_grid, Z, cmap=ListedColormap(['lightblue', 'lightgreen', 'lightyellow']) )

# Plot also the training points
plt.scatter(X[:, 0], X[:, 1], c=y, 
            edgecolor='k', s=20)
plt.xlim(x_grid.min(), x_grid.max())
plt.ylim(y_grid.min(), y_grid.max())
plt.title("KNN 3-Class Classification (k = %d, weights = '%s')"
#           % (n_neighbors, weights))
plt.show()

